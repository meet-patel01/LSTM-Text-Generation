{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a28239ca-fe72-4b2e-8add-32878d3b9845",
      "metadata": {
        "id": "a28239ca-fe72-4b2e-8add-32878d3b9845"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Imports\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "998e7bb6-b887-4ca3-8c85-50ed3f9d3c1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "998e7bb6-b887-4ca3-8c85-50ed3f9d3c1d",
        "outputId": "877a8a04-07f3-4177-a90f-5f5bcfa69f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 2. Load & preprocess dataset\n",
        "\n",
        "# Download the dataset if it doesn't exist\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "with open(path_to_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "# remove punctuation\n",
        "text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "\n",
        "words = text.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5d197072-a52f-4fb5-925a-297893121b35",
      "metadata": {
        "id": "5d197072-a52f-4fb5-925a-297893121b35"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. Tokenization\n",
        "\n",
        "vocab = sorted(set(words))\n",
        "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "encoded = [word_to_idx[word] for word in words]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7c005c41-61f9-44fc-be82-25f3ff07a9f6",
      "metadata": {
        "id": "7c005c41-61f9-44fc-be82-25f3ff07a9f6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 4. Create input-output sequences\n",
        "\n",
        "seq_length = 10\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(len(encoded) - seq_length):\n",
        "    X.append(encoded[i:i + seq_length])\n",
        "    y.append(encoded[i + seq_length])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bcf4c8a6-45d6-46d5-a975-7e02f9b23772",
      "metadata": {
        "id": "bcf4c8a6-45d6-46d5-a975-7e02f9b23772"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c2f96c42-6040-4950-90cb-a05a3ed8c713",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "c2f96c42-6040-4950-90cb-a05a3ed8c713",
        "outputId": "b9edf441-e384-4707-dda4-a5eff3900374"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,644,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m394,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12847\u001b[0m)          │     \u001b[38;5;34m3,301,679\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,644,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12847</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,301,679</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,340,335\u001b[0m (20.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,340,335</span> (20.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,340,335\u001b[0m (20.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,340,335</span> (20.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(seq_length,)),\n",
        "    Embedding(input_dim=vocab_size, output_dim=128),\n",
        "    LSTM(256),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\"\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "edd27590-589c-4ba0-aa25-7ac52fbc3111",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edd27590-589c-4ba0-aa25-7ac52fbc3111",
        "outputId": "42808050-c17a-490c-dabd-cffa39f2c42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 164ms/step - loss: 7.0064 - val_loss: 6.3992\n",
            "Epoch 2/20\n",
            "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 166ms/step - loss: 6.1372 - val_loss: 6.2087\n",
            "Epoch 3/20\n",
            "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 169ms/step - loss: 5.7040 - val_loss: 6.1891\n",
            "Epoch 4/20\n",
            "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 168ms/step - loss: 5.2958 - val_loss: 6.2485\n",
            "Epoch 5/20\n",
            "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 160ms/step - loss: 4.8522 - val_loss: 6.3872\n",
            "Epoch 6/20\n",
            "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 162ms/step - loss: 4.4080 - val_loss: 6.5443\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b62739c9e80>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\n",
        "# 7. Train model\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "823c16d5-3fb0-408c-8905-ec35a85e49e2",
      "metadata": {
        "id": "823c16d5-3fb0-408c-8905-ec35a85e49e2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 8. Text generation function\n",
        "\n",
        "def generate_text(seed_text, next_words=30):\n",
        "    for _ in range(next_words):\n",
        "        tokenized = [word_to_idx.get(w, 0) for w in seed_text.split()]\n",
        "        tokenized = tokenized[-seq_length:]\n",
        "\n",
        "        if len(tokenized) < seq_length:\n",
        "            tokenized = [0] * (seq_length - len(tokenized)) + tokenized\n",
        "\n",
        "        prediction = model.predict(np.array([tokenized]), verbose=0)\n",
        "        next_word = idx_to_word[np.argmax(prediction)]\n",
        "        seed_text += \" \" + next_word\n",
        "\n",
        "    return seed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7e119b0b-c602-48ca-9870-ea8eb0412333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e119b0b-c602-48ca-9870-ea8eb0412333",
        "outputId": "28497129-c429-468b-c691-3915634d4738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "charles dickens man and a man and a man to be a man to be a man to be a man to be a man to be a man to be a man to be a man to be a man to\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 9. Generate sample text\n",
        "\n",
        "seed = \"charles dickens\"\n",
        "print(generate_text(seed, next_words=40))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d3873b04-7cf1-4deb-993c-f5f3133bbe7e",
      "metadata": {
        "id": "d3873b04-7cf1-4deb-993c-f5f3133bbe7e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 10. Save model\n",
        "\n",
        "model.save(\"lstm_gen.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b458d488-1935-4d7b-b6b0-bb649e920dbe",
      "metadata": {
        "id": "b458d488-1935-4d7b-b6b0-bb649e920dbe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}